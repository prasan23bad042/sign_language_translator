# âœ‹ Sign Language Translator

A simple **Sign Language Translator** project that demonstrates how trained model weights can be used to recognize hand signs and produce meaningful output.  
This project focuses on loading pre-trained parameters and generating predictions based on input data.

---

## ğŸ“Œ Project Overview

Sign language is an essential communication medium for the hearing-impaired community.  
This project aims to **translate sign language gestures into understandable output** using pre-trained model weights stored as NumPy arrays.

The model parameters are stored in `.npy` files and are loaded during execution to perform inference.

---

## ğŸ§  Model Files

The following NumPy files represent the trained model parameters:

- `w1.npy` â€“ Weight matrix (Layer 1)
- `b1.npy` â€“ Bias vector (Layer 1)
- `b2.npy` â€“ Bias vector (Layer 2)
- `b3.npy` â€“ Bias vector (Layer 3)
- `b4.npy` â€“ Bias vector (Layer 4)

These files are required for the model to work correctly.

---

## ğŸ–¼ï¸ Output Example

Below is a sample output generated by the Sign Language Translator:

![Project Output](output.jpg)

> The image shows the translated result produced by the model after processing the input sign.

---

## âš™ï¸ Technologies Used

- Python
- NumPy
- Machine Learning (Pre-trained Model Weights)

---

## ğŸš€ How to Run the Project

1. Clone the repository:
   ```bash
   git clone https://github.com/prasan23bad042/sign_language_translator.git
